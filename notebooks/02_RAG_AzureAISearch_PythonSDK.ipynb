{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb299f82-f4b1-4f85-9195-07724f6dd4cb",
   "metadata": {},
   "source": [
    "# RAG Architecture Sample in Python (Azure AI Search)\n",
    "このサンプルノートブックでは以下の RAG アーキテクチャの動作を試すことができます。\n",
    "\n",
    "<img src=\"./images/02_001.png\" width=\"70%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c68a5b",
   "metadata": {},
   "source": [
    "# 事前準備\n",
    "この Python サンプルを実行するには、以下が必要です：\n",
    "- Azure AI Search リソース。エンドポイントとクエリ API キーが必要です。\n",
    "- Azure OpenAI Service にアクセスできる承認済み Azure サブスクリプション\n",
    "- Azure OpenAI Service への `text-embedding-ada-002` Embeddings モデルのデプロイメント。このデモでは、API バージョン `2023-05-15` を使用しています。デプロイ名はモデルと同じ「`text-embedding-ada-002`」を使用しています。\n",
    "- Azure OpenAI Service の接続とモデル情報\n",
    "  - OpenAI API キー\n",
    "  - OpenAI Embeddings モデルのデプロイメント名\n",
    "  - OpenAI API バージョン\n",
    "- Python (この手順はバージョン 3.10.x でテストされています)\n",
    "\n",
    "これらのデモには、Visual Studio Code と [Jupyter extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) を使用できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7c8bef",
   "metadata": {},
   "source": [
    "## パッケージのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d9bbd-e2b9-451a-a872-56f19430d0e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install azure-search-documents==11.4.0\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ef945-8aa3-4538-8bf7-662c01bdf397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import azure.search.documents\n",
    "azure.search.documents.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524420cf",
   "metadata": {},
   "source": [
    "## 必要なライブラリと環境変数のインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c62e8d-9891-4fde-a989-9bb040e1558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient, SearchIndexingBufferedSender  \n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.models import (\n",
    "    QueryAnswerType,\n",
    "    QueryCaptionType,\n",
    "    QueryCaptionResult,\n",
    "    QueryAnswerResult,\n",
    "    SemanticErrorMode,\n",
    "    SemanticErrorReason,\n",
    "    SemanticSearchResultsType,\n",
    "    QueryType,\n",
    "    VectorizedQuery,\n",
    "    VectorQuery,\n",
    "    VectorFilterMode,    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c014e02",
   "metadata": {},
   "source": [
    "## Azure AI Search 接続設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d5c38-7c3d-4849-8079-6f4bcc144a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_endpoint: str = \"<Your search service endpoint>\"\n",
    "service_query_key: str = \"<Your search service query key>\"\n",
    "index_name: str = \"gptkbindex\" #自動構築時のデフォルト設定\n",
    "\n",
    "credential = AzureKeyCredential(service_query_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b043a-044b-458e-9626-7c4cda992103",
   "metadata": {},
   "source": [
    "## Azure OpenAI の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa9e2f-58ba-427d-9634-2d83bff3ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_API_KEY = \"Your OpenAI API Key\"\n",
    "AZURE_OPENAI_ENDPOINT = \"https://<Your OpenAI Service>.openai.azure.com/\"\n",
    "AZURE_OPENAI_CHATGPT_DEPLOYMENT = \"chat\" #自動構築時のデフォルト設定\n",
    "AZURE_OPENAI_EMB_DEPLOYMENT=\"embedding\" #自動構築時のデフォルト設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd993d8-5d4b-4c58-a793-709f58731a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from openai.types.chat import (\n",
    "    ChatCompletion,\n",
    "    ChatCompletionChunk,\n",
    ")\n",
    "\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "  api_key = AZURE_OPENAI_API_KEY,  \n",
    "  api_version = \"2023-05-15\",\n",
    "  azure_endpoint = AZURE_OPENAI_ENDPOINT\n",
    ")\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# タイトルフィールドとコンテンツフィールドのEmbeddingsを生成する関数。\n",
    "def generate_embeddings(text, model=AZURE_OPENAI_EMB_DEPLOYMENT):\n",
    "    return openai_client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e42480-7e59-43c0-8834-30724d4a57db",
   "metadata": {},
   "source": [
    "# 1. 検索クエリ生成\n",
    "最新の質問とチャット履歴をもとに GPT-3.5 Turbo モデルを利用\n",
    "したプロンプトエンジニアリングによって検索クエリを生成します。検索クエリーのフォーマットを合わせるために、Few-shot サンプルを用意して精度を高めています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f54b32-b0a3-44a5-af97-b501d003716e",
   "metadata": {},
   "source": [
    "## 1.1. システムメッセージの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b936b4a9-67a3-480d-a611-b48f7f1917d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query generation prompt\n",
    "query_prompt_template = \"\"\"\n",
    "以下は、過去の会話の履歴と、日本史に関するナレッジベースを検索して回答する必要のあるユーザーからの新しい質問です。\n",
    "会話と新しい質問に基づいて、検索クエリを作成してください。\n",
    "検索クエリには、引用されたファイルや文書の名前（例:info.txtやdoc.pdf）を含めないでください。\n",
    "検索クエリには、括弧 []または<<>>内のテキストを含めないでください。\n",
    "検索クエリを生成できない場合は、数字 0 だけを返してください。\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role': 'system', 'content': query_prompt_template}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc13f7bc-3260-45b6-8ae3-6755dcaa2601",
   "metadata": {},
   "source": [
    "## 1.2. Few-shot サンプルの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d51bfdf-809b-4d31-a35d-f66f57bae832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot Samples\n",
    "query_prompt_few_shots = [\n",
    "    {'role' : 'user', 'content' : '徳川家康ってなにした人  ' },\n",
    "    {'role' : 'assistant', 'content' : '徳川家康 人物 歴史' },\n",
    "    {'role' : 'user', 'content' : '徳川家康の武功を教えてください' },\n",
    "    {'role' : 'assistant', 'content' : '徳川家康 人物 武功 業績' }\n",
    "]\n",
    "\n",
    "for shot in query_prompt_few_shots:\n",
    "    messages.append({'role': shot.get('role'), 'content': shot.get('content')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62fa2b5-570c-4f4f-b292-008be1ecd3ef",
   "metadata": {},
   "source": [
    "## 1.3. ユーザーからの質問"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca3ecf-2f0d-4cbc-a605-a739f03d31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User query\n",
    "user_q = \"源実朝ってどんな人\"\n",
    "messages.append({'role': 'user', 'content': user_q})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51eeae6-2533-4cfc-a8be-592185e0bdac",
   "metadata": {},
   "source": [
    "## 1.4. 送信するメッセージの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af0a574-45ad-4510-9902-2650e4c06d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8246bf33-5839-41d4-a095-ad611debda69",
   "metadata": {},
   "source": [
    "## 1.5. 検索クエリ生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b35179-98b8-4931-bfc1-c7fca5412896",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion: ChatCompletion = openai_client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=AZURE_OPENAI_CHATGPT_DEPLOYMENT,\n",
    "    temperature=0.0,\n",
    "    max_tokens=100,\n",
    "    n=1)\n",
    "\n",
    "query_text = chat_completion.choices[0].message.content\n",
    "print(query_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaba7e2-ffd5-4768-9f71-1971b2190531",
   "metadata": {},
   "source": [
    "# 2. 検索インデックスから関連文書を取得（Retrieve）\n",
    "1. で生成した検索クエリを使用して Azure AI Search で検索を行います。このサンプルでは検索クエリとベクトルの組み合わせでハイブリッド検索を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408f6d06-c7f9-4f54-b551-b6b4a11e30c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonewlines(s: str) -> str:\n",
    "    return s.replace('\\n', ' ').replace('\\r', ' ').replace('[', '【').replace(']', '】')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b71864-30e5-4b5b-a9c3-e0706090dca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)\n",
    "docs = search_client.search(\n",
    "    search_text=query_text,\n",
    "    filter=None,\n",
    "    top=3,\n",
    "    vector_queries=[VectorizedQuery(vector=generate_embeddings(query_text), k_nearest_neighbors=3, fields=\"embedding\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dbd839-96be-43a2-bc7d-fcadf4212af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results =[\" SOURCE:\" + doc['sourcepage'] + \": \" + nonewlines(doc['content']) for doc in docs]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b58d3-8a84-4dc5-9a54-2bbbc47215a4",
   "metadata": {},
   "source": [
    "# 3. ChatGPT を利用した回答の生成\n",
    "\n",
    "Azure AI Search の検索結果やチャット履歴を利用して、コンテキストや内容に応じた回答をを生成します。ここでプロンプトを使って出典を出力するように指示しています。出典には Azure AI Search のファイル名のフィールドの値を使用します。\n",
    "\n",
    "システムメッセージは精度を高めるため、一部英語で記述しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b790dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System message\n",
    "system_message_chat_conversation = \"\"\"\n",
    "日本の鎌倉時代の歴史に関する読解問題に答えるアシスタントです。\n",
    "If you cannot guess the answer to a question from the SOURCE, answer \"I don't know\".\n",
    "Answers must be in Japanese.\n",
    "\n",
    "# Restrictions\n",
    "- The SOURCE prefix has a colon and actual information after the filename, and each fact used in the response must include the name of the source.\n",
    "- To reference a source, use a square bracket. For example, [info1.txt]. Do not combine sources, but list each source separately. For example, [info1.txt][info2.pdf].\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role': 'system', 'content': system_message_chat_conversation}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49832229-cd31-44ef-8d45-86d1f2827b5e",
   "metadata": {},
   "source": [
    "## 3.1. コンテキストを拡張（Augument）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94762ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User query\n",
    "user_q = \"源実朝ってどんな人\"\n",
    "# Context from Azure AI Search\n",
    "context = \"\\n\".join(results)\n",
    "messages.append({'role': 'user', 'content': user_q + \"\\n\\n\" + context}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8a7316-c4bb-4fc2-929c-40af1e5b93f2",
   "metadata": {},
   "source": [
    "## 3.2. 送信するメッセージの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136dde4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a592af27-6f90-4b5b-b763-846d6aacac53",
   "metadata": {},
   "source": [
    "## 3.3. 回答を生成（Generation）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d0753c-8a60-4897-8f3c-e754bff41a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatCompletion で回答を生成する\n",
    "chat_coroutine = openai_client.chat.completions.create(\n",
    "    model=AZURE_OPENAI_CHATGPT_DEPLOYMENT,\n",
    "    messages=messages,\n",
    "    temperature=0.0,\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(chat_coroutine.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4682c-a387-4fbb-9060-cc113e9ad034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
