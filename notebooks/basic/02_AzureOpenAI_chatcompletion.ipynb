{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb299f82-f4b1-4f85-9195-07724f6dd4cb",
   "metadata": {},
   "source": [
    "# Azure OpenAI Service Chat Completion 基礎\n",
    "Chat Completion API は、GPT-35-Turbo および GPT-4 モデルと対話するための新しい専用 API です。この API は、これらのモデルにアクセスするための推奨される方法です。また、新しい GPT-4 モデルにアクセスする唯一の方法でもあります。\n",
    "\n",
    "GPT-35-Turbo モデルと GPT-4 モデルは、会話インターフェイス用に最適化された言語モデルです。これらのモデルの動作は、以前の GPT-3 モデルとは異なります。以前のモデルは**テキストインとテキストアウト**でした。つまり、プロンプト文字列を受け入れ、そのプロンプトを補完する結果を返しました。それとは対照的に、GPT-35-Turbo および GPT-4 モデルは**カンバセーションインとメッセージアウト**です。モデルは、チャットのような特定の形式でフォーマットされた入力を想定し、チャット内のモデルで記述されたメッセージを表す入力候補を返します。この形式はマルチターン会話専用に設計されていますが、チャット以外のシナリオにも適しています。\n",
    "\n",
    "https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?tabs=python-new&pivots=programming-language-chat-completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c68a5b",
   "metadata": {},
   "source": [
    "## 事前準備\n",
    "\n",
    "この Python サンプルを実行するには、以下が必要です：\n",
    "\n",
    "- Azure OpenAI Service にアクセスできる[承認済み](https://aka.ms/oai/access) Azure サブスクリプション\n",
    "- Azure OpenAI Service への GPT-3.5 Turbo / GPT-4 モデルのデプロイメント。\n",
    "- Azure OpenAI Service の接続とモデル情報\n",
    "  - OpenAI API キー\n",
    "  - OpenAI GPT-3.5 Turbo / GPT-4 モデルのデプロイメント名\n",
    "  - OpenAI API バージョン\n",
    "- Python (この手順はバージョン 3.10.x でテストされています)\n",
    "\n",
    "これらのデモには、Visual Studio Code と [Jupyter extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) を使用できます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7c8bef",
   "metadata": {},
   "source": [
    "## パッケージのインストール\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d9bbd-e2b9-451a-a872-56f19430d0e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ef945-8aa3-4538-8bf7-662c01bdf397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524420cf",
   "metadata": {},
   "source": [
    "## 必要なライブラリと環境変数のインポート\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b043a-044b-458e-9626-7c4cda992103",
   "metadata": {},
   "source": [
    "## Azure OpenAI の設定\n",
    "接続情報はセキュリティ面から直接記述するよりも、環境変数や [dotenv](https://pypi.org/project/python-dotenv/) からロードする方法をおすすめします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa9e2f-58ba-427d-9634-2d83bff3ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#os.environ[\"AZURE_OPENAI_API_KEY\"] = \"Your OpenAI API Key\"\n",
    "#os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://<Your OpenAI Service>.openai.azure.com/\"\n",
    "\n",
    "#これは、モデルをデプロイしたときにデプロイメントに選んだカスタム名に対応します。\n",
    "#AZURE_OPENAI_DEPLOYMENT_NAME = \"gpt-35-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dafb36d",
   "metadata": {},
   "source": [
    "## Chat Completion 呼び出し\n",
    "GPT-35-Turbo および GPT-4 モデルは、会話形式の入力を処理するように最適化されています。 `messages` 変数は、システム（`system`）、ユーザー（`user`）、アシスタント（`assistant`）によって示された会話内のさまざまな役割を持つ辞書型の配列を渡します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd993d8-5d4b-4c58-a793-709f58731a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [\n",
    "    {\"role\": \"system\", \"content\": \"日本の歴史について回答するアシスタントです。\"},\n",
    "    {\"role\": \"user\", \"content\": \"鎌倉幕府第三代征夷大将軍の名前を教えて\"}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"), # model = \"deployment_name\"\n",
    "    messages= messages,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41b76bd",
   "metadata": {},
   "source": [
    "### すべてのレスポンス内容を出力\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b603a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86829ece",
   "metadata": {},
   "source": [
    "## 対話の継続\n",
    "Chat Completion API は**ステートレスな API** であり対話の履歴を API 側では持ちません。そのため、対話の履歴を考慮した推論をさせる場合は以下のように過去の結果を配列に含めてリクエストを送信します。\n",
    "\n",
    "- `\"role\": \"assistant\"`: API からの返却値\n",
    "- `\"role\": \"user\"`: ユーザーからの入力値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [\n",
    "    {\"role\": \"system\", \"content\": \"日本の歴史について回答するアシスタントです。\"},\n",
    "    {\"role\": \"user\", \"content\": \"鎌倉幕府第三代征夷大将軍の名前を教えて\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"鎌倉幕府第三代征夷大将軍の名前は源実朝（みなもとのさねとも）です。\"},\n",
    "    {\"role\": \"user\", \"content\": \"源実朝の趣味といえば？\"},\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    messages= messages,\n",
    "    max_tokens=300,\n",
    "    temperature=0.0,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf77fecc",
   "metadata": {},
   "source": [
    "## システムメッセージ\n",
    "システムメッセージ（`system`）は**配列の先頭**に含まれ、モデルに最初の指示を与えます。システムメッセージには、次のようなさまざまな情報を指定できます。\n",
    "\n",
    "- アシスタントの簡単な説明\n",
    "- アシスタントの性格的な特性\n",
    "- アシスタントに従ってもらいたい手順またはルール\n",
    "- FAQ からの関連する質問など、モデルに必要なデータまたは情報\n",
    "\n",
    "ユースケースに合わせてシステムメッセージをカスタマイズすることも、単に基本的な指示を含めることもできます。システムメッセージまたはメッセージは省略可能ですが、最適な結果を得るために、少なくとも基本的なものを含めることをお勧めします。\n",
    "\n",
    "### システム メッセージのフレームワークとテンプレートに関する推奨事項\n",
    "https://learn.microsoft.com/azure/ai-services/openai/concepts/system-message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b9586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [\n",
    "    {\"role\": \"system\", \"content\": \"日本の歴史について簡潔に回答するアシスタントです。回答の最後には回答に関連のある絵文字を含めてください。\"},\n",
    "    {\"role\": \"user\", \"content\": \"源義経が活躍した戦いといえば\"}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    messages= messages,\n",
    "    max_tokens=300,\n",
    "    temperature=0.0,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d782a3e",
   "metadata": {},
   "source": [
    "## メッセージ\n",
    "システムメッセージの後に、ユーザーとアシスタント間の対話を一連のメッセージとして含めることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ae2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [\n",
    "    {\"role\": \"system\", \"content\": \"日本の歴史について簡潔に回答するアシスタントです。回答の最後には回答に関連のある絵文字を含めてください。\"},\n",
    "    {\"role\": \"user\", \"content\": \"源義経が活躍した戦いといえば\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"源義経が活躍した戦いといえば、平治の乱（へいじのらん）が挙げられます。🏹🏯\"},\n",
    "    {\"role\": \"user\", \"content\": \"違いますよ、源義経が活躍した戦いといえば屋島の戦いです\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f2d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"), \n",
    "    messages= messages,\n",
    "    max_tokens=300,\n",
    "    temperature=0.0,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28580464",
   "metadata": {},
   "source": [
    "## 知識を与える\n",
    "関連するデータや情報をシステムメッセージに含めて、モデルに会話の追加コンテキストを与えることもできます。含める必要がある情報の量が少ない場合は、システムメッセージの中にハードコーディングできます。モデルで認識する必要があるデータの量が多い場合は、Embeddings API、または Azure AI Search などの製品を使用して、クエリ時に最も関連性の高い情報を取得できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3666bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "日本の鎌倉時代の歴史について簡潔に回答するアシスタントです。\n",
    "\n",
    "#ルール\n",
    "- 出典から答えが推測できない場合は「わかりません」と答えてください。\n",
    "- 出典に無い答えを勝手に推測しないでください。\n",
    "\n",
    "Context:###\n",
    "源義経: 源義経-Wikipedia.pdf\n",
    "一方、範頼の遠征軍は兵糧と兵船の調達に苦しみ、進軍が停滞してしまう。この状況を知った義経は後白河院に西国出陣を申し出てその許可を得た[注釈 12]。 \n",
    "元暦2年（1185年）2月、新たな軍を編成した義経は、暴風雨の中を少数の船で出撃。通常3日かかる距離を数時間で到着し、讃岐国の瀬戸内海沿いにある平氏の\n",
    "拠点屋島を奇襲し、山や民家を焼き払い、大軍に見せかける作戦で平氏を敗走させた（屋島の戦い）。\n",
    "範頼も九州へ渡ることに成功し、最後の拠点である長門国彦島に拠る平氏の背後を遮断した。義経は水軍を編成して彦島に向かい、3月24日（西暦4月）の壇ノ浦の戦い\n",
    "で勝利して、ついに平氏を滅ぼした。宿願を果たした義経は法皇から戦勝を讃える勅使を受け、一ノ谷、屋島以上の大功を成した立役者として、平氏から\n",
    "取り戻した鏡璽を奉じて4月24日京都に凱旋する。\n",
    "###\n",
    "\n",
    "質問:\n",
    "\"\"\"\n",
    "\n",
    "messages= [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"源義経が活躍した戦いといえば\"},\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"), \n",
    "    messages= messages,\n",
    "    max_tokens=300,\n",
    "    temperature=0.0,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e9448b",
   "metadata": {},
   "source": [
    "## Chat Completion を使用した Few-shot Learning\n",
    "モデルに Few-shot の例を与えることもできます。Few-shot Learning の手法は、プロンプト形式が新しくなったため若干変更されています。ユーザーとアシスタントの間の一連のメッセージを、Few-shot の例としてプロンプトに含められるようになりました。これらの例を使用すると、一般的な質問に対する回答をシード処理してモデルを事前処理したり、特定の動作をモデルに教えたりすることができます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d5f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [\n",
    "    {\"role\": \"system\", \"content\": \"日本の歴史について歴史家風に回答するアシスタントです。回答の最後には回答に関連のある絵文字を含めてください。\"},\n",
    "    {\"role\": \"user\", \"content\": \"源義経が活躍した戦いといえば\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"源義経が活躍した戦いといえば屋島の戦いじゃよ🏹🚣‍♀️\"},\n",
    "    {\"role\": \"user\", \"content\": \"源実朝の趣味といえば？\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"和歌を詠むことじゃよ📜🖋\"},\n",
    "    {\"role\": \"user\", \"content\": \"鎌倉時代の武士の暮らしといえば？\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"武家社会の成立とともに、武士は武家としての生活を送るようになったんじゃ🏯🏹⚔️\"},\n",
    "    {\"role\": \"user\", \"content\": \"源頼家の趣味といえば？\"},\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    messages= messages,\n",
    "    max_tokens=300,\n",
    "    temperature=0.0,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ccf89",
   "metadata": {},
   "source": [
    "## モデル別トークン数計測方法\n",
    "OpenAI の [tiktoken](https://github.com/openai/tiktoken) ライブラリを使用して トークン数を計測します。\n",
    "tiktoken ライブラリをインストールするには以下のコマンドを実行します。\n",
    "\n",
    "`!pip install tiktoken --upgrade`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf2609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# \"gpt-3.5-turbo-0613\",\n",
    "# \"gpt-3.5-turbo-16k-0613\",\n",
    "# \"gpt-4-0314\",\n",
    "# \"gpt-4-32k-0314\",\n",
    "# \"gpt-4-0613\",\n",
    "# \"gpt-4-32k-0613\",\n",
    "model = \"gpt-3.5-turbo-0613\"\n",
    "value = \"源義経が活躍した戦いといえば\"\n",
    "\n",
    "try:\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "except KeyError:\n",
    "    print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "print(\"Tokens:\",len(value))\n",
    "print(encoding.encode(value))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
