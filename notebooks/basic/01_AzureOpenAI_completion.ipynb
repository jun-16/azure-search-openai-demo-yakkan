{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb299f82-f4b1-4f85-9195-07724f6dd4cb",
   "metadata": {},
   "source": [
    "# Azure OpenAI Service Completion 基礎\n",
    "Azure OpenAI Service には、さまざまなタスクに使用できる入力候補（Completion）エンドポイントが用意されています。 このエンドポイントは、シンプルでありながら強力なテキストイン、テキストアウト インターフェイスをすべての Azure OpenAI モデルに提供します。 入力候補を実行するには、**プロンプト**としてテキストを入力します。モデルは入力候補を生成し、コンテキストやパターンとの一致を試みます。「デカルトが言ったように、我思う故に」というプロンプトを API に提供したとします。このプロンプトに基づいて、Azure OpenAI は高い確率で入力候補エンドポイント「我あり」を返します。\n",
    "\n",
    "入力候補を試してみる最も良い方法は、[Azure OpenAI Studio](https://oai.azure.com/) のプレイグラウンドを使用することです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c68a5b",
   "metadata": {},
   "source": [
    "## 事前準備\n",
    "\n",
    "この Python サンプルを実行するには、以下が必要です：\n",
    "\n",
    "- Azure OpenAI Service にアクセスできる[承認済み](https://aka.ms/oai/access) Azure サブスクリプション\n",
    "- Azure OpenAI Service への GPT-3.5 Turbo モデルのデプロイメント。このデモでは、API バージョン `2023-12-01-preview` を使用しています。デプロイ名はモデルと同じ「`gpt-35-turbo-instruct`」を使用しています。\n",
    "- Azure OpenAI Service の接続とモデル情報\n",
    "  - OpenAI API キー\n",
    "  - OpenAI GPT-3.5 Turbo Instruct モデルのデプロイメント名\n",
    "  - OpenAI API バージョン\n",
    "- Python (この手順はバージョン 3.10.x でテストされています)\n",
    "\n",
    "これらのデモには、Visual Studio Code と [Jupyter extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) を使用できます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7c8bef",
   "metadata": {},
   "source": [
    "## パッケージのインストール\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d9bbd-e2b9-451a-a872-56f19430d0e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ef945-8aa3-4538-8bf7-662c01bdf397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524420cf",
   "metadata": {},
   "source": [
    "## 必要なライブラリと環境変数のインポート\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b043a-044b-458e-9626-7c4cda992103",
   "metadata": {},
   "source": [
    "## Azure OpenAI の設定\n",
    "接続情報はセキュリティ面から直接記述するよりも、環境変数や [dotenv](https://pypi.org/project/python-dotenv/) からロードする方法をおすすめします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa9e2f-58ba-427d-9634-2d83bff3ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#from dotenv import load_dotenv\n",
    "#load_dotenv()\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"Your OpenAI API Key\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://<Your OpenAI Service>.openai.azure.com/\"\n",
    "\n",
    "#これは、モデルをデプロイしたときにデプロイメントに選んだカスタム名に対応します。gpt-35-turbo-instructディプロイメントを使用してください。\n",
    "AZURE_OPENAI_INSTRUCT_DEPLOYMENT = \"gpt-35-turbo-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dafb36d",
   "metadata": {},
   "source": [
    "## Hello world!\n",
    "\n",
    "### テキスト生成 - アイデア提案\n",
    "モデルで実行できる最も強力で最も簡単なタスクの 1 つは、入力の新しいアイデアやバージョンを生成することです。ミステリー小説を書いていて、ストーリーのアイデアが必要だとします。モデルにアイデアのリストを提供すると、モデルはそのリストにアイデアを追加しようとします。モデルは、ほんの少数の例に基づいて、ビジネス プラン、キャラクターの説明、マーケティング スローガンなどを作成することができます。\n",
    "\n",
    "https://learn.microsoft.com/azure/ai-services/openai/how-to/completions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd993d8-5d4b-4c58-a793-709f58731a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2023-12-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a completion call to generate an answer\n",
    "prompt = \"アイスクリームショップのキャッチコピーを考えてください\"\n",
    "response = client.completions.create(\n",
    "    model=AZURE_OPENAI_INSTRUCT_DEPLOYMENT, prompt=prompt, max_tokens=100\n",
    ")\n",
    "print(prompt)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf3d166",
   "metadata": {},
   "source": [
    "上の例ではコンテキストが少ししか提供されないため、モデルが期待される結果を常に返すとは限らないのは正常です。 応答が予期しないまたは切り捨てられたように見える場合は、トークンの最大数 `max_tokens` を調整できます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53ddf62",
   "metadata": {},
   "source": [
    "## コード補完\n",
    "補完機能を使用して React コード コンポーネントの作成を支援する方法を示しています。まず、モデルにコードを送信します。開き括弧 `(` でコードの入力を停止します。モデルは不完全なコードを HeaderComponent の定数定義を補完するためのトリガーと解釈します。さらにモデルは対応する React ライブラリを理解しているため、このコード定義を補完できます。\n",
    "\n",
    "https://learn.microsoft.com/azure/ai-services/openai/how-to/completions#complete-partial-text-and-code-inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aeeeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation prompt\n",
    "prompt = \"\"\"\n",
    "import React from 'react';\n",
    "const HeaderComponent = () => (\n",
    "\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=AZURE_OPENAI_INSTRUCT_DEPLOYMENT,\n",
    "    prompt=prompt,\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    top_p=1.0,\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b009c",
   "metadata": {},
   "source": [
    "## テキストの要約\n",
    "モデルはテキストのコンテキストを把握し、それをさまざまな方法で言い換えることができます。このデモでは、モデルがテキストのブロックを受け取り、小学生でも理解できる説明を作成します。この例は、モデルが言語を深く理解していることを示しています。\n",
    "\n",
    "https://learn.microsoft.com/azure/ai-services/openai/how-to/completions#summarize-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation prompt\n",
    "prompt = \"\"\"\n",
    "以下の説明を 100 字程度で要約してください。\n",
    "\n",
    "###\n",
    "中性子星は質量が太陽程度、直径20 km程度、大気の厚さはわずか1 m程度で、中性子が主な成分の天体である。\n",
    "密度は太陽の10^14倍以上もあるとされている。およそ10^9 t/cm3とその桁外れに大きい密度のため、中性子星の\n",
    "表面重力は地球の表面重力の2×10^11倍もの大きさがあり、脱出速度は 1/3 c にも達する。中性子星は大質量の\n",
    "恒星の超新星爆発によってその中心核が圧縮された結果形成されるが、中性子星として存在できる質量にはトルマン\n",
    "・オッペンハイマー・ヴォルコフ限界と呼ばれる上限値があり、それを超えるとブラックホールとなる。\n",
    "上限の質量は、理論的に太陽質量の1.5倍から2.5倍の範囲にあると考えられており、2010年に約1.97倍の中性子星、\n",
    "2013年には約2.01倍の中性子星が確認されている。下限は太陽質量の0.1倍から0.2倍程度。\n",
    "###\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=AZURE_OPENAI_INSTRUCT_DEPLOYMENT,\n",
    "    prompt=prompt,\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    top_p=1.0,\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation prompt\n",
    "prompt = \"\"\"\n",
    "以下の説明を6歳の子供でも理解できるように分かりやすく要約してください。\n",
    "子供が分からない単語は、分かりやすい言葉に置き換えてください。\n",
    "\n",
    "###\n",
    "中性子星は質量が太陽程度、直径20 km程度、大気の厚さはわずか1 m程度で、中性子が主な成分の天体である。\n",
    "密度は太陽の10^14倍以上もあるとされている。およそ10^9 t/cm3とその桁外れに大きい密度のため、中性子星の\n",
    "表面重力は地球の表面重力の2×10^11倍もの大きさがあり、脱出速度は 1/3 c にも達する。中性子星は大質量の\n",
    "恒星の超新星爆発によってその中心核が圧縮された結果形成されるが、中性子星として存在できる質量にはトルマン\n",
    "・オッペンハイマー・ヴォルコフ限界と呼ばれる上限値があり、それを超えるとブラックホールとなる。\n",
    "上限の質量は、理論的に太陽質量の1.5倍から2.5倍の範囲にあると考えられており、2010年に約1.97倍の中性子星、\n",
    "2013年には約2.01倍の中性子星が確認されている。下限は太陽質量の0.1倍から0.2倍程度。\n",
    "###\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=AZURE_OPENAI_INSTRUCT_DEPLOYMENT,\n",
    "    prompt=prompt,\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    top_p=1.0,\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4682c-a387-4fbb-9060-cc113e9ad034",
   "metadata": {},
   "source": [
    "Azure OpenAI API は対話のたびに新しい出力を生成するため、表示される入力候補の結果は異なる場合があります。 プロンプトが同じであっても、API を呼び出すたびに少しずつ異なる入力候補が得られる可能性があります。 この動作は、`temperature` の設定で制御できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c637d018",
   "metadata": {},
   "source": [
    "## テキストの分類\n",
    "テキスト分類器を作成するには、タスクの説明を提示し、いくつかの例を示します。この例では、テキストメッセージのセンチメントを分類する方法をモデルに示しています。センチメントとは、テキスト内の全体的な感情や表現のことです。\n",
    "\n",
    "https://learn.microsoft.com/azure/ai-services/openai/how-to/completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e981fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "これはテキストメッセージのセンチメント分類器です。\n",
    "\n",
    "Message: \"新しいアドベンチャー映画が大好きです！\"\n",
    "Sentiment: ポジティブ\n",
    "\n",
    "Message: \"携帯のバッテリーが切れるのは嫌だ\" \n",
    "Sentiment: 否定的\n",
    "\n",
    "Message: \"今日は👍\"\n",
    "Sentiment: ポジティブ\n",
    "\n",
    "Message: \"これは記事へのリンクです\"\n",
    "Sentiment: 中立\n",
    "\n",
    "Message: \"この新しいミュージックビデオは非現実的だ\"\n",
    "Sentiment: \n",
    "\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=AZURE_OPENAI_INSTRUCT_DEPLOYMENT,\n",
    "    prompt=prompt,\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    top_p=1.0,\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662e1fd4",
   "metadata": {},
   "source": [
    "### 1 回の API 呼び出しから複数の結果を得る\n",
    "分類器の作成方法を理解したので、最初のデモを拡張して、効率を高めましょう。分類器を使用して、1 回の API 呼び出しから複数の結果を取得できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640d8a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "これはテキストメッセージのセンチメント分類器です。\n",
    "\n",
    "Message: \"新しいアドベンチャー映画が大好きです！\"\n",
    "Sentiment: ポジティブ\n",
    "\n",
    "Message: \"携帯のバッテリーが切れるのは嫌だ\" \n",
    "Sentiment: 否定的\n",
    "\n",
    "Message: \"今日は👍\"\n",
    "Sentiment: ポジティブ\n",
    "\n",
    "Message: \"これは記事へのリンクです\"\n",
    "Sentiment: 中立\n",
    "\n",
    "メッセージテキスト\n",
    "1. \"新しいアドベンチャー映画が大好きだった！\"\n",
    "2. \"携帯の電池が切れるのが嫌だ\"\n",
    "3. \"今日は👍\"\n",
    "4. \"これが記事へのリンクです\"\n",
    "5. \"この新しいミュージックビデオは非現実的だ\"\n",
    "\n",
    "メッセージのセンチメント評価\n",
    "1: ポジティブ\n",
    "2: 否定的\n",
    "3: ポジティブ\n",
    "4: 中立\n",
    "5: ポジティブ\n",
    "\n",
    "メッセージテキスト\n",
    "1. \"彼は宿題が嫌いです\"\n",
    "2. 「タクシーが遅れている。彼女は怒っている😠\"\n",
    "3. 「週末が待ち遠しい！！」\n",
    "4. \"うちの猫がかわいい ❤️❤️\"\n",
    "5. \"チョコバナナ食べてみよう\"\n",
    "\n",
    "メッセージのセンチメント評価\n",
    "1:\n",
    "\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=AZURE_OPENAI_INSTRUCT_DEPLOYMENT,\n",
    "    prompt=prompt,\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    top_p=1.0,\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b74fd6",
   "metadata": {},
   "source": [
    "## テキストの翻訳\n",
    "日本語のフレーズをフランス語に変換する方法をモデルに指示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d91c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Japanese: 私はフランス語は話せません。\n",
    "French: Je ne parle pas français.\n",
    "Japanese: また会おう！\n",
    "French: À tout à l'heure!\n",
    "Japanese: いいレストランはどこですか？\n",
    "French: Où est un bon restaurant?\n",
    "Japanese: 空いている部屋はありますか？\n",
    "French: Quelles chambres avez-vous de disponible?\n",
    "Japanese:最寄りの駅はどこですか？\n",
    "\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=AZURE_OPENAI_INSTRUCT_DEPLOYMENT,\n",
    "    prompt=prompt,\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    top_p=1.0,\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a20fd65",
   "metadata": {},
   "source": [
    "### 絵文字への変換\n",
    "映画の題名をテキストから絵文字に変換します。この例は、モデルがパターンを把握して、他の文字を使用するだけの適応力を持っていることを示しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa305385",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Carpool Time: 👨👴👩🚗🕒\n",
    "Robots in Cars: 🚗🤖\n",
    "Super Femme: 👸🏻👸🏼👸🏽👸🏾👸🏿\n",
    "Webs of the Spider: 🕸🕷🕸🕸🕷🕸\n",
    "The Three Bears: 🐻🐼🐻\n",
    "Mobster Family: 👨👩👧🕵🏻‍♂️👲💥\n",
    "Arrows and Swords: 🏹🗡🗡🏹\n",
    "Snowmobiles:\n",
    "\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=AZURE_OPENAI_INSTRUCT_DEPLOYMENT,\n",
    "    prompt=prompt,\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    top_p=1.0,\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c158a28a",
   "metadata": {},
   "source": [
    "## 質問応答（Q&A）\n",
    "コンテキストを使って業界独自の文書、企業内 FAQ など、GPT モデルが知らない様々な文書も質問応答の対象にできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2546b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "以下のテキストを使って下記の質問に答えてください。もし答えがない場合には、「私は知らない」と答えてください。\n",
    "\n",
    "コンテキスト:\n",
    "###\n",
    "Surface Book が空の状態から完全に充電されるまで、2 ～ 4 時間かかります。\n",
    "Surface Book を充電しながらゲームやビデオ ストリーミングのような電力消費の\n",
    "多い活動に Surface を使用している場合、さらに時間がかかる可能性があります。\n",
    "電源アダプターに付いている USB ポートを使って、Surface Book の充電中に\n",
    "スマートフォンなどの他のデバイスを充電することもできます。電源アダプターの\n",
    "USB ポートは充電専用であり、データ転送用ではありません。\n",
    "###\n",
    "\n",
    "質問: Surface Book の充電時間を節約するにはどうすればよいか。\n",
    "回答: \n",
    "\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=AZURE_OPENAI_INSTRUCT_DEPLOYMENT,\n",
    "    prompt=prompt,\n",
    "    max_tokens=200,\n",
    "    temperature=0.0,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb2bda2",
   "metadata": {},
   "source": [
    "### テンプレート化\n",
    "プロンプトをテンプレート化することで、プログラムとの統合や管理をしやすくすることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a6cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "以下のテキストを使って下記の質問に答えてください。もし答えがない場合には、「私は知らない」と答えてください。\n",
    "\n",
    "コンテキスト: \n",
    "###\n",
    "{input}\n",
    "###\n",
    "\n",
    "質問: {question}\n",
    "回答: \n",
    "\"\"\"\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    input=\"Surface Book が空の状態から完全に充電されるまで、2 ～ 4 時間かかります。Surface Book を充電しながらゲームやビデオ ストリーミングのような電力消費の多い活動に Surface を使用している場合、さらに時間がかかる可能性があります。電源アダプターに付いている USB ポートを使って、Surface Book の充電中にスマートフォンなどの他のデバイスを充電することもできます。電源アダプターの USB ポートは充電専用であり、データ転送用ではありません。\",\n",
    "    question=\"Surface Book の充電時間を節約するにはどうすればよいか。\",\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5187e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.completions.create(\n",
    "    model=AZURE_OPENAI_INSTRUCT_DEPLOYMENT,\n",
    "    prompt=prompt,\n",
    "    max_tokens=200,\n",
    "    temperature=0.0,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c9b596",
   "metadata": {},
   "source": [
    "## エンティティ抽出\n",
    "テキストの中からエンティティ（名前や地名、組織など）を抽出するデモです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "下記のEメールの内容から、差出人の名前とその人の住所を抽出してください。\n",
    "\n",
    "###\n",
    "鈴木さん、セミナーで一緒にお話できて本当嬉しいです。加藤さんの話も、とてもすばらしかったです。\n",
    "書籍の件、ありがとうございます。私の住所は、東京都港区港南２丁目１６−３です。\n",
    "\n",
    "山田太郎\n",
    "###\n",
    "\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=AZURE_OPENAI_INSTRUCT_DEPLOYMENT,\n",
    "    prompt=prompt,\n",
    "    max_tokens=200,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4133f1d3",
   "metadata": {},
   "source": [
    "## Zero-shot CoT（思考の連鎖）\n",
    "例示なしでタスクの解法を誘導する手法（「一歩ずつ順番に考えてください」原文「Let's think step by step」によって正しい回答へ誘導）です。ユーザーの複雑な質問や指示をタスクに分解して、それぞれのタスクごとに解決策を講じることができる非常に重要なテクニックです。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a311783",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "質問 :ジョンはりんごを5個持っていて、2個食べて、さらに5個買って、3個を友達に上げたとしたら、ジョンはりんごを何個持っていますか？\n",
    "\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=AZURE_OPENAI_INSTRUCT_DEPLOYMENT,\n",
    "    prompt=prompt,\n",
    "    max_tokens=200,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93792ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "質問 :ジョンはりんごを5個持っていて、2個食べて、さらに5個買って、3個を友達に上げたとしたら、ジョンはりんごを何個持っていますか？\n",
    "\n",
    "一歩ずつ順番に考えてください。\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=AZURE_OPENAI_INSTRUCT_DEPLOYMENT,\n",
    "    prompt=prompt,\n",
    "    max_tokens=200,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
