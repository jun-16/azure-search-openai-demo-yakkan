{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb299f82-f4b1-4f85-9195-07724f6dd4cb",
   "metadata": {},
   "source": [
    "# Semantic Kernel in Python\n",
    "[Semantic Kernel](https://github.com/microsoft/semantic-kernel) (SK) は Microsoft が OSS として発表した、大規模言語モデル (LLM) をアプリにすばやく簡単に統合できる SDK です。Semantic Kernel は従来のプログラミング言語と最新のLLM AI \"プロンプト\" を簡単に組み合わせることができ、テンプレート化、チェーン化、埋め込みベースのメモリー、およびプランニング機能を備えています。\n",
    "\n",
    "本サンプルコードは、Semantic Kernel 公式 [Notebook](https://github.com/microsoft/semantic-kernel/tree/main/python/notebooks) に基づいています。Microsoft Learn によるドキュメントは[こちら](https://learn.microsoft.com/semantic-kernel/overview/)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32dd86d",
   "metadata": {},
   "source": [
    "## 事前準備\n",
    "\n",
    "この Python サンプルを実行するには、以下が必要です：\n",
    "\n",
    "- Azure OpenAI Service にアクセスできる[承認済み](https://aka.ms/oai/access) Azure サブスクリプション\n",
    "- Azure OpenAI Service への GPT-3.5 Turbo モデルのデプロイメント。\n",
    "- Azure OpenAI Service の接続とモデル情報\n",
    "  - OpenAI API キー\n",
    "  - OpenAI GPT-3.5 Turbo モデルのデプロイメント名\n",
    "  - OpenAI API バージョン\n",
    "- Python (この手順はバージョン 3.10.x でテストされています)\n",
    "\n",
    "これらのデモには、Visual Studio Code と [Jupyter extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) を使用できます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf5a47a",
   "metadata": {},
   "source": [
    "## パッケージのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d9bbd-e2b9-451a-a872-56f19430d0e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install semantic-kernel==0.4.5.dev0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37ce97",
   "metadata": {},
   "source": [
    "## Azure OpenAI の設定\n",
    "接続情報はセキュリティ面から直接記述するよりも、以下の情報を記載した `.env` ファイルからロードする方法がおすすめです。\n",
    "\n",
    "### Azure OpenAI の場合\n",
    "以下の情報が必要です。\n",
    "```\n",
    "AZURE_OPENAI_API_KEY=\"...\"\n",
    "AZURE_OPENAI_ENDPOINT=\"https://...\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME=\"...\"\n",
    "```\n",
    "### OpenAI の場合\n",
    "以下の情報が必要です。\n",
    "```\n",
    "OPENAI_API_KEY=\"sk-...\"\n",
    "OPENAI_ORG_ID=\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3043ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AZURE_OPENAI_API_KEY = \"Your OpenAI API Key\"\n",
    "#AZURE_OPENAI_ENDPOINT = \"https://<Your OpenAI Service>.openai.azure.com/\"\n",
    "#AZURE_OPENAI_DEPLOYMENT_NAME = \"gpt-35-turbo\"\n",
    "#AZURE_OPENAI_EMB_DEPLOYMENT_NAME = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f83eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding, AzureChatCompletion, AzureTextEmbedding\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# Azure OpenAI Service を使用するかどうか\n",
    "useAzureOpenAI = True\n",
    "\n",
    "# カーネルが使用する OpenAI サービスの設定\n",
    "if useAzureOpenAI:\n",
    "    deployment_name, api_key, endpoint = sk.azure_openai_settings_from_dot_env() # 環境変数からロードする場合\n",
    "    azure_chat_service = AzureChatCompletion(deployment_name=deployment_name, endpoint=endpoint, api_key=api_key)\n",
    "    #azure_text_embedding = AzureTextEmbedding(deployment_name=AZURE_OPENAI_EMB_DEPLOYMENT_NAME, endpoint=endpoint, api_key=api_key)\n",
    "    kernel.add_chat_service(\"chat_completion\", azure_chat_service)\n",
    "    #kernel.add_text_embedding_generation_service(\"ada\", azure_text_embedding)\n",
    "else:\n",
    "    # OpenAIの場合\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env() # 環境変数からロードする場合\n",
    "    oai_text_service = OpenAIChatCompletion(ai_model_id=\"gpt-3.5-turbo\", api_key=api_key, org_id=org_id)\n",
    "    kernel.add_text_completion_service(\"chat_completion\", oai_text_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d15f9b",
   "metadata": {},
   "source": [
    "## 要約\n",
    "プロンプトを使って、コンテンツを要約するためのセマンティック関数を作ってみましょう。この関数は要約するテキストを入力として受け取ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "以下の説明を6歳の子供でも理解できるように分かりやすく要約してください。\n",
    "子供が分からない単語は、分かりやすい言葉に置き換えてください。\n",
    "\n",
    "{{$input}}\n",
    "\"\"\"\n",
    "\n",
    "summarize = kernel.create_semantic_function(prompt_template=prompt, max_tokens=400, temperature=0.0, top_p=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa96121",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "中性子星は質量が太陽程度、直径20 km程度、大気の厚さはわずか1 m程度で、中性子が主な成分の天体である。\n",
    "密度は太陽の10^14倍以上もあるとされている。およそ10^9 t/cm3とその桁外れに大きい密度のため、中性子星の\n",
    "表面重力は地球の表面重力の2×10^11倍もの大きさがあり、脱出速度は 1/3 c にも達する。中性子星は大質量の\n",
    "恒星の超新星爆発によってその中心核が圧縮された結果形成されるが、中性子星として存在できる質量にはトルマン\n",
    "・オッペンハイマー・ヴォルコフ限界と呼ばれる上限値があり、それを超えるとブラックホールとなる。\n",
    "上限の質量は、理論的に太陽質量の1.5倍から2.5倍の範囲にあると考えられており、2010年に約1.97倍の中性子星、\n",
    "2013年には約2.01倍の中性子星が確認されている。下限は太陽質量の0.1倍から0.2倍程度。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4ccda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize(input_text)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7886bcb5",
   "metadata": {},
   "source": [
    "## 履歴を考慮したチャットボット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_prompt = \"\"\"\n",
    "日本の鎌倉時代の歴史に関する読解問題に答えるアシスタントです。\n",
    "明確な指示を与えることも、答えがわからない場合は「わからない」と言うこともできます。\n",
    "\n",
    "{{$history}}\n",
    "User: {{$user_input}}\n",
    "ChatBot: \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a927b7",
   "metadata": {},
   "source": [
    "### セマンティック関数の登録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd3c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_function = kernel.create_semantic_function(\n",
    "    prompt_template=sk_prompt,\n",
    "    function_name=\"ChatBot\",\n",
    "    max_tokens=2000,\n",
    "    temperature=0.7,\n",
    "    top_p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ab03f0",
   "metadata": {},
   "source": [
    "### コンテキストを初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8203f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = kernel.create_new_context()\n",
    "context[\"history\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d78e04",
   "metadata": {},
   "source": [
    "### チャットを開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc15c70a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "context[\"user_input\"] = \"源実朝ってどんな人\"\n",
    "bot_answer = await chat_function.invoke_async(context=context)\n",
    "print(bot_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bbf2a2",
   "metadata": {},
   "source": [
    "### 出力で履歴を更新する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context[\"history\"] += f\"\\nUser: {context['user_input']}\\nChatBot: {bot_answer}\\n\"\n",
    "print(context[\"history\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dfe9a9",
   "metadata": {},
   "source": [
    "### 継続的なチャットのための関数を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ca0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat(input_text: str) -> None:\n",
    "    # コンテキスト変数に新しいメッセージを保存\n",
    "    print(f\"User: {input_text}\")\n",
    "    context[\"user_input\"] = input_text\n",
    "\n",
    "    # ユーザーからのメッセージを処理し、回答を得る\n",
    "    answer = await chat_function.invoke_async(context=context)\n",
    "\n",
    "    # レスポンスを表示する\n",
    "    print(f\"ChatBot: {answer}\")\n",
    "\n",
    "    # Append the new interaction to the chat history\n",
    "    context[\"history\"] += f\"\\nUser: {input_text}\\nChatBot: {answer}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a42965",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"源実朝が編纂した書物は何ですか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c289630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"源実朝が編纂したのは金槐和歌集ですよ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90df820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"金槐和歌集はどんな書物ですか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"違いますね、源実朝のみの歌を集めた歌集です\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f8c597",
   "metadata": {},
   "source": [
    "しばらくのチャットの後、`history` コンテキストに蓄積された完全なチャット履歴を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6712d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(context[\"history\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b85b12c",
   "metadata": {},
   "source": [
    "## プラグイン（旧スキル）のロード\n",
    "スキルとそのすべての関数をファイルからインポートします。`./samples/skills/FunSkill` ディレクトリの構造がそのままスキルの構成となります。\n",
    "\n",
    "https://learn.microsoft.com/semantic-kernel/agents/plugins/?tabs=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c767604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: サンプルフォルダのスキルを使用する\n",
    "skills_directory = \"./samples/skills\"\n",
    "\n",
    "funFunctions = kernel.import_semantic_skill_from_directory(skills_directory, \"FunSkill\")\n",
    "\n",
    "jokeFunction = funFunctions[\"Joke\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e714d1ef",
   "metadata": {},
   "source": [
    "ロードしたセマンティック関数は以下のようにして実行することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8134304",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = sk.ContextVariables()\n",
    "context[\"style\"] = \"日本のお笑いの文化を理解したうえで\"\n",
    "\n",
    "result = jokeFunction(\"忍者について\", variables=context)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b50a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 非同期実行の場合\n",
    "context = sk.ContextVariables()\n",
    "context[\"style\"] = \"日本のお笑いの文化を理解したうえで\"\n",
    "\n",
    "result = await jokeFunction.invoke_async(\"忍者について\", variables=context)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba591541",
   "metadata": {},
   "source": [
    "## Basic プランナー\n",
    "まずは基本的なプランナーを見てみましょう。`BasicPlanner` は JSON ベースの実行計画を生成し、提供された指示や質問を順次解決することを目的とし、順番に評価されます。\n",
    "\n",
    "https://learn.microsoft.com/semantic-kernel/agents/planners/?tabs=python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2bbf51",
   "metadata": {},
   "source": [
    "### 計算機コアスキルのロード\n",
    "プランナーは利用可能なスキルを知る必要があります。ここでは、ライブラリ内に事前定義されているコアスキルである `MathSkill` をロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61058b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.core_skills import MathSkill\n",
    "\n",
    "kernel.import_skill(MathSkill(), \"math\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25be18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planning.basic_planner import BasicPlanner\n",
    "\n",
    "planner = BasicPlanner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"202 と 990 の合計はいくらか？\"\n",
    "\n",
    "basic_plan = await planner.create_plan_async(ask, kernel)\n",
    "\n",
    "print(basic_plan.generated_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824087d9",
   "metadata": {},
   "source": [
    "`BasicPlanner` が質問を受け取り、それを JSON ベースのプランに変換して、AI がカーネルが利用できるスキルを利用して、このタスクを解決する方法を説明していることがわかります。\n",
    "\n",
    "上の実行計画でわかるように、AI はユーザーの要求を満たすためにどの関数を呼び出すべきかを決定しました。プランの各ステップの出力は、次の関数への入力となります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7995d66c",
   "metadata": {},
   "source": [
    "### プランの実行\n",
    "実行計画ができたので、それを実行してみましょう！ `BasicPlanner` には `execute_plan` という関数があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb8cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await planner.execute_plan_async(basic_plan, kernel)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c34cc",
   "metadata": {},
   "source": [
    "## スキルを組み合わせる\n",
    "### プランナーへのスキルの提供\n",
    "プランナーは利用可能なスキルを知る必要があります。ここでは、ディスク上で定義した `SummarizeSkill` と `WriterSkill` にアクセスできるようにします。これには多くのセマンティック関数が含まれ、プランナーはそのサブセットをインテリジェントに選択します。\n",
    "\n",
    "ネイティブ関数を含めることもできます。ここでは `TextSkill` を追加します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6718f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "\n",
    "skills_directory = \"./samples/skills/\"\n",
    "summarize_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"SummarizeSkill\")\n",
    "writer_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"WriterSkill\")\n",
    "text_skill = kernel.import_skill(TextSkill(), \"TextSkill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78358dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"\"\"明日はバレンタインデーだ。デートのアイデアをいくつか考えないと。\n",
    "彼女はシェークスピアが好きなので、彼のスタイルで書いてください。彼女はフランス語を話すので、フランス語で書きましょう。\n",
    "あとテキストを大文字に変換しなさい。\n",
    "\"\"\"\n",
    "\n",
    "basic_plan = await planner.create_plan_async(ask, kernel)\n",
    "\n",
    "print(basic_plan.generated_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c415e966",
   "metadata": {},
   "source": [
    "インラインスキルも定義して、プランナーが使用できるようにしましょう。必ず、関数名とスキル名を付けてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78bedae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Rewrite the above in the style of Shakespeare.\n",
    "\"\"\"\n",
    "shakespeareFunction = kernel.create_semantic_function(\n",
    "    prompt_template=sk_prompt,\n",
    "    function_name=\"shakespeare\",\n",
    "    skill_name=\"ShakespeareSkill\",\n",
    "    max_tokens=2000,\n",
    "    temperature=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097c1cb1",
   "metadata": {},
   "source": [
    "新たなプランを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f505e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_plan = await planner.create_plan_async(ask, kernel)\n",
    "print(new_plan.generated_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078f393",
   "metadata": {},
   "source": [
    "新しく作成したプランを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93329e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await planner.execute_plan_async(new_plan, kernel)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
